#Below is a self‑contained Python script that reads a unit‑level CSV 
#(one row per mapping unit) containing the TBDeff slope and the auxiliary geological parameters, computes Pearson correlations and bootstrap confidence intervals, determines correlation sign, and writes a Table_2 CSV and a human_readable Markdown table.
#- Input: the script expects the per‑unit TBDeff slope (computed from the four normalized channels) and the auxiliary parameters (TiO₂, FeO, Bolometric T anomaly, Regolith T anomaly, Plagioclase, Hydrogen, Crustal thickness, Free‑air gravity, OMAT) in a single unit_aggregates.csv.
#- Computation: for each parameter it computes the Pearson correlation with slope, estimates 95% bootstrap confidence intervals for the correlation, and a two‑sided bootstrap p‑value. The script records the sign (+/−) and attaches the geological interpretation strings you provided.
#- Output: table2_summary.csv (numeric results and CIs) and table2_markdown.md (manuscript‑ready table). These files correspond to Table 2 in the paper.
#- Reproducibility: N_BOOT and RANDOM_SEED are explicit; include these values and the script in your code archive and cite them in Methods (Section 3.6).

#This script reads the unit‑level slope dataset (unit_aggregates.csv), 
#computes Pearson correlations between slope and auxiliary geological parameters, 
#estimates bootstrap confidence intervals and p‑values, and outputs both a numeric summary 
#(table2_summary.csv) and a human‑readable Markdown table (table2_markdown.md). 
#These files correspond directly to Table2 in the manuscript.

#ANNOTATED WORKFLOW

# User parameters
INPUT_CSV = "unit_aggregates.csv"
UNIT_COL = "UNIT_ID"
SLOPE_COL = "TBDeff_slope"

# Parameters to test correlations against slope
PARAMETERS = {
    "TiO2_wt": "TiO2 abundance",
    "FeO_wt": "FeO abundance",
    ...
}

# Geological interpretations for each parameter
INTERPRETATIONS = {
    "TiO2 abundance": "High Ti basalts amplify surface excursions",
    ...
}

# Bootstrap settings
N_BOOT = 10000
RANDOM_SEED = 20251201
np.random.seed(RANDOM_SEED)

#RAW CODE

"""
make_table2.py

Inputs:
 - CSV with one row per mapping unit containing:
    UNIT_ID, TBDeff_slope, TiO2_wt, FeO_wt, Bolometric_T_anom,
    Regolith_T_anom, Plagioclase_wt, Hydrogen_ppm, Crustal_thickness_km,
    FreeAirGravity_mGal, OMAT

Outputs:
 - table2_summary.csv : columns [Parameter, Pearson_r, r_ci_2.5, r_ci_97.5, Sign, Interpretation]
 - table2_markdown.md : human readable table for manuscript
 - prints summary to console

Dependencies:
 pip install numpy pandas scipy
"""
import json
import numpy as np
import pandas as pd
from scipy import stats

# ---------------- USER PARAMETERS ----------------
INPUT_CSV = "unit_aggregates.csv"   # edit to your aggregated CSV
UNIT_COL = "UNIT_ID"
SLOPE_COL = "TBDeff_slope"

# Map parameter column names in your CSV to short labels used in Table 2
PARAMETERS = {
    "TiO2_wt": "TiO2 abundance",
    "FeO_wt": "FeO abundance",
    "Bolometric_T_anom": "Bolometric T anomaly",
    "Regolith_T_anom": "Regolith T anomaly",
    "Plagioclase_wt": "Plagioclase abundance",
    "Hydrogen_ppm": "Hydrogen content",
    "Crustal_thickness_km": "Crustal thickness (Mod. 3)",
    "FreeAirGravity_mGal": "Free air gravity an. (GRAIL)",
    "OMAT": "Optical maturity (OMAT)"
}

# Geological interpretation mapping (customise text if desired)
INTERPRETATIONS = {
    "TiO2 abundance": "High Ti basalts amplify surface excursions",
    "FeO abundance": "Basaltic composition enhances radiative response",
    "Bolometric T anomaly": "Elevated diurnal variability in basaltic terrains",
    "Regolith T anomaly": "Independent confirmation of surface amplification",
    "Plagioclase abundance": "Feldspathic terrains suppress excursions",
    "Hydrogen content": "Fine-grained mantling reduces shallow variability",
    "Crustal thickness (Mod. 3)": "Thick crust correlates with suppressed slopes",
    "Free air gravity an. (GRAIL)": "Neg. anomalies mark consolidated feldspathic domains",
    "Optical maturity (OMAT)": "Low maturity linked to ejecta mantling and suppression"
}

# Bootstrap settings
N_BOOT = 10000
RANDOM_SEED = 20251201
np.random.seed(RANDOM_SEED)

# ---------------- Load data ----------------
df = pd.read_csv(INPUT_CSV)
# Keep only rows with slope and at least one parameter
df = df[[UNIT_COL, SLOPE_COL] + list(PARAMETERS.keys())].dropna(subset=[SLOPE_COL])
n_units = len(df)
if n_units == 0:
    raise SystemExit("No units with slope values found in input CSV.")

slope = df[SLOPE_COL].values

# ---------------- Functions ----------------
def pearson_and_bootstrap(x, y, n_boot=N_BOOT):
    """Return observed r, bootstrap 2.5/97.5 percentiles, and two-sided bootstrap p-value."""
    # remove pairs with NaN
    mask = ~np.isnan(x) & ~np.isnan(y)
    x0 = x[mask]; y0 = y[mask]
    if len(x0) < 3:
        return np.nan, np.nan, np.nan, np.nan
    obs_r, _ = stats.pearsonr(x0, y0)
    boot_r = np.empty(n_boot)
    n = len(x0)
    for i in range(n_boot):
        idx = np.random.choice(n, size=n, replace=True)
        try:
            r, _ = stats.pearsonr(x0[idx], y0[idx])
        except Exception:
            r = np.nan
        boot_r[i] = r
    ci = np.nanpercentile(boot_r, [2.5, 97.5])
    # two-sided bootstrap p-value: proportion of bootstraps with sign opposite to observed
    p_boot = np.mean(np.sign(boot_r) != np.sign(obs_r))
    return float(obs_r), float(ci[0]), float(ci[1]), float(p_boot)

# ---------------- Compute correlations ----------------
rows = []
for col, label in PARAMETERS.items():
    if col not in df.columns:
        print(f"Warning: parameter column '{col}' not found in CSV; skipping.")
        continue
    param_vals = df[col].values
    obs_r, ci_lo, ci_hi, p_boot = pearson_and_bootstrap(slope, param_vals)
    sign = "+" if obs_r > 0 else ("-" if obs_r < 0 else "0")
    interp = INTERPRETATIONS.get(label, "")
    rows.append({
        "Parameter": label,
        "Pearson_r": obs_r,
        "r_ci_2.5": ci_lo,
        "r_ci_97.5": ci_hi,
        "Bootstrap_p_two_sided": p_boot,
        "Sign": sign,
        "Interpretation": interp
    })

# ---------------- Save outputs ----------------
out_df = pd.DataFrame(rows)
out_df = out_df[["Parameter", "Sign", "Pearson_r", "r_ci_2.5", "r_ci_97.5", "Bootstrap_p_two_sided", "Interpretation"]]
out_df.to_csv("table2_summary.csv", index=False)

# Also write a Markdown table for manuscript copy/paste
md_lines = []
md_lines.append("| Parameter | Corr. with slope | Geological interpretation |")
md_lines.append("|---|---:|---|")
for _, r in out_df.iterrows():
    corr_sign = r["Sign"]
    md_lines.append(f"| {r['Parameter']} | {corr_sign} | {r['Interpretation']} |")

with open("table2_markdown.md", "w") as fh:
    fh.write("\n".join(md_lines))

# Print brief summary
print("Table 2 summary written to: table2_summary.csv")
print(out_df[["Parameter", "Sign", "Pearson_r", "r_ci_2.5", "r_ci_97.5"]].to_string(index=False))